---
title: 'MCP 맛보기'
publishedAt: '2025-07-16'
summary: 'MCP에 대해서, '
tags: '#MCP, #AI'
author: 'Stoic Park'
readingTime: '5분'
draft: true
---

## MCP가 뭘까

대 AI 시대를 살아가는 요즘 자연스럽게 `MCP`라는 단어를 많이 접하게 됩니다.

하지만 정작 MCP가 무엇인지에 대해서는 잘 모르는 경우가 많은데요.

그러한 사람이 바로 저였고, 자주 접하게 되는 이 MCP를 애써 외면하지 말고 이게 무엇이고, 어떻게 활용하는 것인지에 대해서 알아보는 시간을 가져보고자 합니다.

MCP는 보통 백엔드 관점으로 많이 알려져있고, 저 또한 그런 느낌으로 알고 있었는데, 이번에 MCP에 대해서 조금씩 알아가면서 프론트엔드 관점에서의 MCP에 대한 내용들도 접하게 됐습니다.

그래서 MCP에 대해서 조금씩 찾아보다보니 흥미로운 부분이 많아, 이번 포스팅에서 내용을 기록해보고자 합니다.

## MCP(Model Context Protocol)

> MCP is an open protocol that standardizes how applications provide context to LLMs.
> Think of MCP like a USB-C port for AI applications.
> Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.

위 문장은 가이드 문서에 있는 MCP에 대한 소개 문장입니다.
한글로 번역해보면 다음과 같습니다.

> MCP는 애플리케이션이 LLM에 제공하는 컨텍스트를 표준화하는 오픈 프로토콜입니다.
> MCP를 AI 애플리케이션의 USB-C 포트와 비유해보세요. USB-C는 다양한 주변 장치와 액세서리에 연결하는 표준화된 방법을 제공하듯이, MCP는 AI 모델을 다양한 데이터 소스와 도구에 연결하는 표준화된 방법을 제공합니다.

핵심은 MCP는 AI 모델을 다양한 데이터 소스와 도구에 연결하는 표준화된 방법을 제공합니다. 인 것 같습니다.

동시에 왜 MCP를 사용해야하는가에 대한 설명도 나와있는데요

> MCP helps you build agents and complex workflows on top of LLMs. LLMs frequently need to integrate with data and tools, and MCP provides:
>
> - A growing list of pre-built integrations that your LLM can directly plug into
> - The flexibility to switch between LLM providers and vendors
> - Best practices for securing your data within your infrastructure

위 문장은 MCP를 사용하면 LLM을 더 유연하게 사용할 수 있고, 데이터를 보호할 수 있다는 내용입니다.

## MCP를 사용하는 이유

앞서 가이드문서에서 MCP를 사용하는 이유에 대해서 알아보았는데요. 조금 더 자세히 알아보도록 하겠습니다.

요즘 다양한 AI도구들이 나오고 있는데요. 이런 도구들을 사용하면서, 내 LLM이 내 말을 좀더 잘 이해했으면 좋겠다라는 생각을 자주 했었습니다.

실제로 LLM은 프롬프트 만으로도 충분히 잘 작동하는 경우가 많습니다. 하지만, LLM이 내 의도대로 보다 정확하게 동작하기 위해서는 정확하고 많은 양의 컨텍스트가 꾸준히, 그리고 구조적으로 주입되어야 합니다.

그렇다면.. LLM은 왜 컨텍스트가 필요할까요?

GPT에게 이것에 대해서 물어봤더니 아래와 같은 예시를 들어 설명해주었습니다.

예를 들어, 회사에서 사내 위키를 기반으로 답변하는 챗봇을 만든다고 해본다면

이때 LLM에게 우리는 이렇게 말합니다

"우리 회사 연차 정책 알려줘"

이 요청에 대해 LLM이 답변을 하기 위해서는 연차와 관련된 사내 문서를 이미 알고 있어야 합니다.

그러나, 이 사내 문서는 프롬프트 한 줄로 전달하기 어렵고, 크기도 클 수 있습니다.

그렇기 때문에, 우리가 할 일은 다음과 같습니다

- 사내 문서 내용을 적절히 분할
- 어떤 문서가 지금 질문과 관련 있는지 판단
- 그 일부를 LLM에게 동적으로 주입

이 과정을 컨텍스트 주입(Context Injection)이라고 합니다.
그리고 이것을 매번 직접 구현하는 것은 굉장히 번거롭고 복잡한 작업이지요..

그렇다면 LLM에 컨텍스트를 주입하는 기존 방법은 어땠을까요? 아래와 같은 과정을 거쳤을 겁니다.

- 클라이언트에서 사용자 질문을 감지
- 관련 데이터 검색
- 컨텍스트 + 질문을 조합해 프롬프트 생성
- LLM에게 요청

글로 봤을 때는 매우 합리적이고 단순해보이지만, 실제로는 그렇지 않습니다
프로젝트마다 구성 로직이 달라져야 하고,
LLM 공급자가 바뀌면 요청 방식도 바뀌고, 데이터 보안 이슈도 생기고...
결국 각자 독자적인 연결 방식을 구현하느라 중복 개발이 발생하게 될 겁니다!

여기서 MCP가 등장합니다.

LLM과 데이터를 어떻게 연결할 것인가! 를 하나의 표준으로 묶어주는 것이 MCP의 역할입니다.

- 프롬프트에 어떤 컨텍스트를 넣을지 자동화
- LLM 공급자(GPT, Claude 등)가 바뀌어도 동일한 구조 사용 가능
- 데이터 접근 로직을 분리해서 보안성을 유지
- 컨텍스트와 도구(tool)를 함께 연결할 수 있음

정리하자면,

- LLM은 똑똑하지만 문맥을 모르면 답변을 잘 못한다
- 문맥을 주입하는 구조는 복잡하고 반복적
- MCP는 이런 연결을 표준화하고 간소화 해주는 역할

그래서 MCP를 도입하면 복잡한 컨텍스트 구성 로직을 단순화하고, 다양한 데이터와 LLM을 안정적으로 연결할 수 있게 해줍니다.

LLM에 대해서 잘 모르는 제가 이해한 바로 비유해서 설명해보면

- LLM은 똑똑한 비서!
- MCP는 요청한 업무에 필요한 자료나 도구를 자동으로, 쳬계적으로 전달해주는 도구! 비서의 비서! 라고 저는 이해했습니다.

## MCP의 구조

가이드에서 제시하는 보편적인 MCP의 구조는 다음과 같습니다.

<img
 width="757"
 height="521"
 alt="Image"
 src="/images/2025-07-17-23-09-24.png"
/>

- MCP 호스트(MCP Hosts): Claude Desktop, IDE, 또는 MCP를 통해 데이터에 접근하고자 하는 AI 도구와 같은 프로그램들
- MCP 클라이언트(MCP Clients): 서버와 1:1 연결을 유지하는 프로토콜 클라이언트
- MCP 서버(MCP Servers): 표준화된 Model Context Protocol을 통해 각각 특정 기능을 노출하는 경량 프로그램
- 로컬 데이터 소스(Local Data Sources): MCP 서버가 안전하게 접근할 수 있는 내 컴퓨터의 파일, 데이터베이스, 서비스 등
- 원격 서비스(Remote Services): MCP 서버가 연결할 수 있는 인터넷상의 외부 시스템(API 등)

## MCP 사용해보기

어느정도 MCP에 대해서 알게 된 것 같습니다.
그렇다면 실제로는 어떻게 사용되는지 한번 알아보도록 하겠습니다.

제가 사용하는 AI 에디터인 Cursor.ai 를 기준으로 살펴보도록 하겠습니다.

{/* 그럼 MCP 관점에서 Cursor가 어떤 식으로 동작하고, 어떻게 Claude나 GPT와 연결되는지를 예시로 설명드릴게요. */}

MCP 관점에서 Cursor는 Claude, GPT-4, Mixtral 등을 백엔드로 사용하는 AI 기반 코드 에디터 입니다.

그 자체로 MCP 호스트 역할을 하는 것이지요!

내가 작성한 코드를 읽고 AI에게 질문을 할 수 있는 인터페이스를 제공합니다!

<div style={{ display: 'flex', justifyContent: 'center' }}>
 <img
  width="400"
  height="200"
  alt="Image"
  src="/images/2025-07-18-18-38-49.png"
 />
</div>

하지만.. 위와 같이 질문이 명확하지 않다면..! 내가 딱 원하는 답변을 얻지 못하는 경우가 빈번합니다

<div style={{ display: 'flex', justifyContent: 'center' }}>
 <img
  width="400"
  height="200"
  alt="Image"
  src="/images/2025-07-18-18-53-51.png"
 />
</div>

위처럼 `Cursor`는 자체적으로 LLM모델을 선택할 수 있고, 또한 컨텍스트를 주입할 수 있습니다.

예를 들어, Claude 모델을 선택하고 `Cursor`에게 질문을 하나 해보겠습니다

"이 함수를 리팩토링해줘!!"

이때 Claude는 단순히 질문 텍스트만 받는 게 아니라,

`Cursor`가 MCP 클라이언트 역할을 하며 다음과 같은 컨텍스트를 함께 전달합니다

- 현재 열려 있는 파일의 전체 코드

- 최근 수정된 코드 범위

- 관련된 import 파일 내용

- 프로젝트 설정 파일 (예: package.json, tsconfig.json)

- 터미널 로그나 테스트 결과 등

이런 컨텍스트가 MCP를 통해 Claude에게 구조화된 형태로 전달되기 때문에,
Claude는 더 정교한 응답을 해줄 수 있습니다.

다시보면,

cursor를 사용하는것 자체가 MCP 를 적용한 상태라고 볼 수 있습니다.

MCP가 뭐야뭐야 어떻게 사용하는거야 했지만

사실은 이미 이런 형태로 사용하고 있었던 것이지요!

```
[Cursor 에디터] (MCP Host)
 └─ 내 코드, 파일 구조, 콘솔 로그
       ↓
[MCP 클라이언트]
 └─ Context Pack 생성 및 Claude에게 전달
       ↓
[Claude] (LLM Provider)
 └─ 코드를 충분히 이해한 후 응답 생성
```

음..

{/* 작성중... */}

## 프론트엔드에서의 MCP

MCP에 대해서 알아보면서 가장 관심있게 보고 있는 주제입니다.

부족한 배경지식이지만, 구글링을 하다보면 다양한 프론트엔드 관점에서의 MCP 활용 예시들이 나오는데요!

조금씩 훑어보면서, 프론트엔드 관점에서의 MCP 활용 예시들을 알아보도록 하겠습니다.

작성중...

## MCP 도입시 주의할 점

작성중...

## 앞으로의 전망과 나의 생각

작성중...

```

MCP의 구조 살펴보기
→ 현재 그림과 설명 기반으로 구조 설명 (이미 잘 작성됨)
→ 각 구성 요소의 역할을 조금 더 실사용 시나리오로 설명 추가

MCP의 실제 활용 예시

Claude + VS Code (코드 컨텍스트 제공)

Local PDF를 기반으로 답변하는 RAG 앱

Slack에서 LLM이 사내 문서를 기반으로 응답하도록 구성
→ 간단한 시나리오 그림이나 YAML/JSON 예제 추가

프론트엔드 개발자 입장에서 본 MCP

LLM 기반 기능을 UI에 통합할 때 필요한 컨텍스트 연결

예: 웹 앱에서 사용자 세션 로그를 LLM에게 전달

브라우저 extension, 로컬 서버 기반 프록시 등과 연동 가능성

fetch 또는 websocket을 통해 MCP 서버와 통신하는 구조

MCP 빠르게 따라하기

공식 MCP 예제 저장소 클론

로컬 MCP 서버 실행, 클라이언트 설정, Claude 또는 GPT와 연동

실습 코드 조각 (config.yaml, routes, tools.json 등)

CLI 도구나 SDK가 있다면 함께 소개

MCP를 도입할 때 주의할 점

보안 (LLM과 연결된 민감한 데이터)

네트워크 환경 (로컬 vs 원격)

LLM 공급자별 차이 (Anthropic, OpenAI 등)

앞으로의 전망과 나의 생각

프론트엔드 개발자가 LLM과 연결될 UI/UX를 설계할 때

단순 프롬프트가 아니라, "컨텍스트 흐름"까지 설계하게 될 것

MCP는 그 흐름을 표준화해주는 핵심 기술이라는 인사이트 공유

```

```

```
